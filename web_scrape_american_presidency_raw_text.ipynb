{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_american_presidency_project_raw_text\n",
    "* [The American presidency project](http://www.presidency.ucsb.edu/ws/index.php?pid=25800&st=&st1=) archives every public document by each president, including speeches, executive orders, press conferences, news breifings, economic reports, etc. Currently there are 129,483 documents in total, dating back from 1789 to March 2018.  \n",
    "\n",
    "* This file retrieves these documents using beauitful soup in units of 1000 docs, saving each unit in a pickle file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " '''\n",
    " get raw text of a single document from given url\n",
    " '''\n",
    "    \n",
    "def get_a_doc(url):\n",
    "    content = ''\n",
    "    try:\n",
    "        soup = BeautifulSoup(requests.get(url).text, \"html5lib\")\n",
    "        content = soup.find('span', class_=\"displaytext\").text\n",
    "    except:\n",
    "        content = \"Invalid pageID\"\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "page ids range from 1 to 129483 as 129483 is the total number of presidential documents.\n",
    "this function retreives documents with id in the given range, for example, within range(1000, 2001), \n",
    "then saves the result in a pickle file\n",
    "~/proj4/data/presidency_docs_1000_to_2000.pkl\n",
    "'''\n",
    "\n",
    "def get_multiple_docs(page_id_range):\n",
    "\n",
    "    result = []\n",
    "    # a few page ids don't work for some reason; remember those in a list\n",
    "    invalid_ids = []\n",
    "    \n",
    "    for i in page_id_range: \n",
    "        url = 'http://www.presidency.ucsb.edu/ws/index.php?pid='+str(i)\n",
    "        content = get_a_doc(url)\n",
    "        if content != 'Invalid pageID':\n",
    "            result.append(get_a_doc(url))\n",
    "        else:\n",
    "            invalid_ids.append[i]\n",
    "        \n",
    "    filename = '/home/ubuntu/proj4/data/presidency_docs_'+str(min(page_id_range))+'_to_'+str(max(page_id_range))+'.pkl'\n",
    "    with open(filename, 'wb') as fp:\n",
    "        pickle.dump(result, fp)\n",
    "        \n",
    "    if len(invalid_ids) > 0:\n",
    "        filename = '/home/ubuntu/proj4/data/invalid_ids_presidency_docs_'+str(min(page_id_range))+'_to_'+str(max(page_id_range))+'.pkl'\n",
    "        with open(filename, 'wb') as fp:\n",
    "            pickle.dump(invalid_ids, fp) \n",
    "        \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1001\n",
      "1001 2001\n",
      "2001 3001\n",
      "3001 4001\n",
      "4001 5001\n",
      "5001 6001\n",
      "6001 7001\n",
      "7001 8001\n",
      "8001 9001\n",
      "9001 10001\n",
      "10001 11001\n",
      "11001 12001\n",
      "12001 13001\n",
      "13001 14001\n",
      "14001 15001\n",
      "15001 16001\n",
      "16001 17001\n",
      "17001 18001\n",
      "18001 19001\n",
      "19001 20001\n",
      "20001 21001\n",
      "21001 22001\n",
      "22001 23001\n",
      "23001 24001\n",
      "24001 25001\n",
      "25001 26001\n",
      "26001 27001\n",
      "27001 28001\n",
      "28001 29001\n",
      "29001 30001\n",
      "30001 31001\n",
      "31001 32001\n",
      "32001 33001\n",
      "33001 34001\n",
      "34001 35001\n",
      "35001 36001\n",
      "36001 37001\n",
      "37001 38001\n",
      "38001 39001\n",
      "39001 40001\n",
      "40001 41001\n",
      "41001 42001\n",
      "42001 43001\n",
      "43001 44001\n",
      "44001 45001\n",
      "45001 46001\n",
      "46001 47001\n",
      "47001 48001\n",
      "48001 49001\n",
      "49001 50001\n",
      "50001 51001\n",
      "51001 52001\n",
      "52001 53001\n",
      "53001 54001\n",
      "54001 55001\n",
      "55001 56001\n",
      "56001 57001\n",
      "57001 58001\n",
      "58001 59001\n",
      "59001 60001\n",
      "60001 61001\n",
      "61001 62001\n",
      "62001 63001\n",
      "63001 64001\n",
      "64001 65001\n",
      "65001 66001\n",
      "66001 67001\n",
      "67001 68001\n",
      "68001 69001\n",
      "69001 70001\n",
      "70001 71001\n",
      "71001 72001\n",
      "72001 73001\n",
      "73001 74001\n",
      "74001 75001\n",
      "75001 76001\n",
      "76001 77001\n",
      "77001 78001\n",
      "78001 79001\n",
      "79001 80001\n",
      "80001 81001\n",
      "81001 82001\n",
      "82001 83001\n",
      "83001 84001\n",
      "84001 85001\n",
      "85001 86001\n",
      "86001 87001\n",
      "87001 88001\n",
      "88001 89001\n",
      "89001 90001\n",
      "90001 91001\n",
      "91001 92001\n",
      "92001 93001\n",
      "93001 94001\n",
      "94001 95001\n",
      "95001 96001\n",
      "96001 97001\n",
      "97001 98001\n",
      "98001 99001\n",
      "99001 100001\n",
      "100001 101001\n",
      "101001 102001\n",
      "102001 103001\n",
      "103001 104001\n",
      "104001 105001\n",
      "105001 106001\n",
      "106001 107001\n",
      "107001 108001\n",
      "108001 109001\n",
      "109001 110001\n",
      "110001 111001\n",
      "111001 112001\n",
      "112001 113001\n",
      "113001 114001\n",
      "114001 115001\n",
      "115001 116001\n",
      "116001 117001\n",
      "117001 118001\n",
      "118001 119001\n",
      "119001 120001\n",
      "120001 121001\n",
      "121001 122001\n",
      "122001 123001\n",
      "123001 124001\n",
      "124001 125001\n",
      "125001 126001\n",
      "126001 127001\n",
      "127001 128001\n",
      "129001 129484\n"
     ]
    }
   ],
   "source": [
    "# get start points and end points for ranges\n",
    "\n",
    "start_pts = [i for i in range(1,128000,1000)]\n",
    "end_pts = [ i+1000 for i in start_pts]\n",
    "last_interval = (129001, 129484)\n",
    "\n",
    "start_pts.append(last_interval[0])\n",
    "end_pts.append(last_interval[1])\n",
    "\n",
    "for i in range(len(start_pts)):\n",
    "    print(start_pts[i], end_pts[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get all docoments\n",
    "'''\n",
    "\n",
    "def scrape_all():\n",
    "    \n",
    "    start_pts = [i for i in range(12001,128000,1000)]\n",
    "    end_pts = [ i+1000 for i in start_pts]\n",
    "    last_interval = (129001, 129484)\n",
    "\n",
    "    start_pts.append(last_interval[0])\n",
    "    end_pts.append(last_interval[1])\n",
    "    \n",
    "    \n",
    "    for i in range(len(start_pts)):\n",
    "        get_multiple_docs(range(start_pts[i], end_pts[i]))\n",
    "        \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
